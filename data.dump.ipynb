{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2 in c:\\python312\\lib\\site-packages (2.9.10)\n",
      "Requirement already satisfied: sqlalchemy in c:\\python312\\lib\\site-packages (2.0.35)\n",
      "Requirement already satisfied: python-dotenv in c:\\python312\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: pandas in c:\\python312\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\python312\\lib\\site-packages (from sqlalchemy) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\python312\\lib\\site-packages (from sqlalchemy) (3.1.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\python312\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2 sqlalchemy python-dotenv pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load enviornment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "db_user  = os.environ.get('POSTGRES_USER')\n",
    "db_password  = os.environ.get('POSTGRES_PASSWORD')\n",
    "db_name  = os.environ.get('POSTGRES_DB')\n",
    "db_host  = 'localhost'\n",
    "db_port  = '5432'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database Postgres connection successful\n"
     ]
    }
   ],
   "source": [
    "# use psycopg to make connection\n",
    "try:\n",
    "    connection = psycopg2.connect(\n",
    "        host=db_host,\n",
    "        port=db_port,\n",
    "        dbname=db_name,\n",
    "        user=db_user,\n",
    "        password=db_password\n",
    "    )\n",
    "    print(\"Database Postgres connection successful\")\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error connecting to the database\",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(f'postgresql+psycopg2://{db_user}:{db_password}@{db_host}:{db_port}/{db_user}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files_directory = \"./data\"\n",
    "\n",
    "if not os.path.exists(csv_files_directory):\n",
    "    print(f'Directory {csv_files_directory} does not exist')\n",
    "else:\n",
    "    csv_files = [f for f in os.listdir(csv_files_directory) if f.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CUST_AZ12.csv',\n",
       " 'cust_info.csv',\n",
       " 'LOC_A101.csv',\n",
       " 'prd_info.csv',\n",
       " 'PX_CAT_G1V2.csv',\n",
       " 'sales_details.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cleaned and overwritten: ./data\\CUST_AZ12.csv\n",
      "‚úÖ Cleaned and overwritten: ./data\\cust_info.csv\n",
      "‚úÖ Cleaned and overwritten: ./data\\LOC_A101.csv\n",
      "‚úÖ Cleaned and overwritten: ./data\\prd_info.csv\n",
      "‚úÖ Cleaned and overwritten: ./data\\PX_CAT_G1V2.csv\n",
      "‚úÖ Cleaned and overwritten: ./data\\sales_details.csv\n",
      "üöÄ All CSVs cleaned and updated successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Path where your CSVs are\n",
    "csv_folder = './data'\n",
    "\n",
    "# List of CSV files\n",
    "csv_files = [\n",
    "    \"CUST_AZ12.csv\",\n",
    "    \"cust_info.csv\",\n",
    "    \"LOC_A101.csv\",\n",
    "    \"prd_info.csv\",\n",
    "    \"PX_CAT_G1V2.csv\",\n",
    "    \"sales_details.csv\"\n",
    "    \n",
    "]\n",
    "\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(csv_folder, file)\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Drop duplicates\n",
    "        df_cleaned = df.drop_duplicates()\n",
    "        \n",
    "        # Overwrite the original file\n",
    "        df_cleaned.to_csv(file_path, index=False)\n",
    "        \n",
    "        print(f\"‚úÖ Cleaned and overwritten: {file_path}\")\n",
    "    else:\n",
    "        print(f\"‚ùå File not found: {file_path}\")\n",
    "\n",
    "print(\"üöÄ All CSVs cleaned and updated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÑ CUST_AZ12.csv\n",
      "CID         0\n",
      "BDATE       0\n",
      "GEN      1472\n",
      "dtype: int64\n",
      "\n",
      "üìÑ cust_info.csv\n",
      "cst_id                   4\n",
      "cst_key                  0\n",
      "cst_firstname            8\n",
      "cst_lastname             7\n",
      "cst_marital_status       7\n",
      "cst_gndr              4578\n",
      "cst_create_date          4\n",
      "dtype: int64\n",
      "\n",
      "üìÑ LOC_A101.csv\n",
      "CID        0\n",
      "CNTRY    332\n",
      "dtype: int64\n",
      "\n",
      "üìÑ prd_info.csv\n",
      "prd_id            0\n",
      "prd_key           0\n",
      "prd_nm            0\n",
      "prd_cost          2\n",
      "prd_line         17\n",
      "prd_start_dt      0\n",
      "prd_end_dt      197\n",
      "dtype: int64\n",
      "\n",
      "üìÑ PX_CAT_G1V2.csv\n",
      "ID             0\n",
      "CAT            0\n",
      "SUBCAT         0\n",
      "MAINTENANCE    0\n",
      "dtype: int64\n",
      "\n",
      "üìÑ sales_details.csv\n",
      "sls_ord_num     0\n",
      "sls_prd_key     0\n",
      "sls_cust_id     0\n",
      "sls_order_dt    0\n",
      "sls_ship_dt     0\n",
      "sls_due_dt      0\n",
      "sls_sales       8\n",
      "sls_quantity    0\n",
      "sls_price       7\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for file in csv_files:\n",
    "    file_path = os.path.join(csv_folder, file)\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        # Check nulls\n",
    "        null_counts = df.isnull().sum()\n",
    "\n",
    "        print(f\"\\nüìÑ {file}\")\n",
    "        print(null_counts)\n",
    "    else:\n",
    "        print(f\"‚ùå File not found: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dropped nulls from CUST_AZ12.csv\n",
      "‚úÖ Dropped nulls from cust_info.csv\n",
      "‚úÖ Dropped nulls from LOC_A101.csv\n",
      "‚úÖ Dropped nulls from prd_info.csv\n",
      "‚úÖ Dropped nulls from PX_CAT_G1V2.csv\n",
      "‚úÖ Dropped nulls from sales_details.csv\n",
      "\n",
      "‚úÖ All files cleaned for nulls only.\n"
     ]
    }
   ],
   "source": [
    "for file in csv_files:\n",
    "    file_path = os.path.join(csv_folder, file)\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Drop rows with any null values\n",
    "        df = df.dropna()\n",
    "\n",
    "        # Save it back\n",
    "        df.to_csv(file_path, index=False)\n",
    "\n",
    "        print(f\"‚úÖ Dropped nulls from {file}\")\n",
    "    else:\n",
    "        print(f\"‚ùå File not found: {file_path}\")\n",
    "\n",
    "print(\"\\n‚úÖ All files cleaned for nulls only.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating table 'cust_az12' with query: \n",
      "            CREATE TABLE IF NOT EXISTS \"cust_az12\" (\n",
      "                \"CID\" TEXT, \"BDATE\" TEXT, \"GEN\" TEXT\n",
      "            );\n",
      "        \n",
      "‚úÖ Data from ./data\\CUST_AZ12.csv loaded into 'cust_az12' successfully.\n",
      "Creating table 'cust_info' with query: \n",
      "            CREATE TABLE IF NOT EXISTS \"cust_info\" (\n",
      "                \"cst_id\" TEXT, \"cst_key\" TEXT, \"cst_firstname\" TEXT, \"cst_lastname\" TEXT, \"cst_marital_status\" TEXT, \"cst_gndr\" TEXT, \"cst_create_date\" TEXT\n",
      "            );\n",
      "        \n",
      "‚úÖ Data from ./data\\cust_info.csv loaded into 'cust_info' successfully.\n",
      "Creating table 'loc_a101' with query: \n",
      "            CREATE TABLE IF NOT EXISTS \"loc_a101\" (\n",
      "                \"CID\" TEXT, \"CNTRY\" TEXT\n",
      "            );\n",
      "        \n",
      "‚úÖ Data from ./data\\LOC_A101.csv loaded into 'loc_a101' successfully.\n",
      "Creating table 'prd_info' with query: \n",
      "            CREATE TABLE IF NOT EXISTS \"prd_info\" (\n",
      "                \"prd_id\" TEXT, \"prd_key\" TEXT, \"prd_nm\" TEXT, \"prd_cost\" TEXT, \"prd_line\" TEXT, \"prd_start_dt\" TEXT, \"prd_end_dt\" TEXT\n",
      "            );\n",
      "        \n",
      "‚úÖ Data from ./data\\prd_info.csv loaded into 'prd_info' successfully.\n",
      "Creating table 'px_cat_g1v2' with query: \n",
      "            CREATE TABLE IF NOT EXISTS \"px_cat_g1v2\" (\n",
      "                \"CID\" TEXT, \"CAT\" TEXT, \"SUBCAT\" TEXT, \"MAINTENANCE\" TEXT\n",
      "            );\n",
      "        \n",
      "‚úÖ Data from ./data\\PX_CAT_G1V2.csv loaded into 'px_cat_g1v2' successfully.\n",
      "Creating table 'sales_details' with query: \n",
      "            CREATE TABLE IF NOT EXISTS \"sales_details\" (\n",
      "                \"sls_ord_num\" TEXT, \"sls_prd_key\" TEXT, \"sls_cust_id\" TEXT, \"sls_order_dt\" TEXT, \"sls_ship_dt\" TEXT, \"sls_due_dt\" TEXT, \"sls_sales\" TEXT, \"sls_quantity\" TEXT, \"sls_price\" TEXT\n",
      "            );\n",
      "        \n",
      "‚úÖ Data from ./data\\sales_details.csv loaded into 'sales_details' successfully.\n",
      "üîí Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define correctly\n",
    "csv_files_directory = \"./data\"  # <- folder where CSVs are stored\n",
    "csv_files = [\n",
    "    \"CUST_AZ12.csv\",\n",
    "    \"cust_info.csv\",\n",
    "    \"LOC_A101.csv\",\n",
    "    \"prd_info.csv\",\n",
    "    \"PX_CAT_G1V2.csv\",\n",
    "    \"sales_details.csv\"\n",
    "]\n",
    "\n",
    "# Your PostgreSQL connection\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "\n",
    "db_user = 'postgres'\n",
    "db_password = 'example'\n",
    "db_host = 'localhost'\n",
    "db_port = '5432'\n",
    "db_name = 'postgres'\n",
    "\n",
    "connection = psycopg2.connect(\n",
    "    database=db_name,\n",
    "    user=db_user,\n",
    "    password=db_password,\n",
    "    host=db_host,\n",
    "    port=db_port\n",
    ")\n",
    "\n",
    "engine = create_engine(f'postgresql+psycopg2://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}')\n",
    "\n",
    "\n",
    "def load_csv_to_postgresql(csv_file, table_name, conn, engine):\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file)\n",
    "\n",
    "        # Dynamically create the table\n",
    "        columns = ', '.join([f'\"{col}\" TEXT' for col in df.columns])\n",
    "\n",
    "        create_table_query = f\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS \"{table_name}\" (\n",
    "                {columns}\n",
    "            );\n",
    "        \"\"\"\n",
    "\n",
    "        print(f\"Creating table '{table_name}' with query: {create_table_query}\")\n",
    "\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(create_table_query)\n",
    "            conn.commit()\n",
    "\n",
    "        # Load Data\n",
    "        df.to_sql(table_name, engine, if_exists=\"replace\", index=False, method='multi', chunksize=1000)\n",
    "        print(f\"‚úÖ Data from {csv_file} loaded into '{table_name}' successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading {csv_file}: {e}\")\n",
    "\n",
    "\n",
    "# Start uploading\n",
    "if not os.path.exists(csv_files_directory):\n",
    "    print(f\"‚ùå Directory {csv_files_directory} does not exist.\")\n",
    "else:\n",
    "    for csv_file in csv_files:\n",
    "        csv_file_path = os.path.join(csv_files_directory, csv_file)\n",
    "        table_name = os.path.splitext(csv_file)[0].lower()  # table names lowercase\n",
    "        load_csv_to_postgresql(csv_file=csv_file_path, table_name=table_name, conn=connection, engine=engine)\n",
    "\n",
    "if connection:\n",
    "    connection.close()\n",
    "    print(\"üîí Database connection closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
